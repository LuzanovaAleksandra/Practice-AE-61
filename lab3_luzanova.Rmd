---
title: "NONLINEAR REGRESSION"
output:
  word_document: default
  html_notebook: default
  pdf_document: default
  html_document: default
---

# Download the data
```{r}
#Source files are here
#setwd('D:/luzanova')

##Features scaling is included in the packages we will work with

#Download the files
f_train <- read.csv2('crime_train.csv', header = TRUE, encoding = 'UNICOD')
f_test <- read.csv2('crime_test.csv', header = TRUE, encoding = 'UNICOD')
```
#Висновок: окремо завантажені навчальна і тестова вибірки.
# Decision Tree Regression

## Fitting
```{r}
# install.packages('rpart')
library(rpart)
model_dt <- rpart(Homicide ~ Population, f_train, control = rpart.control(minsplit = 10))
plot(model_dt)
text(model_dt, pos = 1, cex = 0.75, col = 1, font = 1)
```
#Висновок: побудовано дерево рішень, екзогенна змінна – Population.

## Predicting
```{r}
p_dt <- predict(model_dt, f_test)

train_mse_dt <- sum((f_train$Homicide-predict(model_dt, f_train))^2)/length(f_train$Homicide)
test_mse_dt <- sum((f_test$Homicide-p_dt)^2)/length(p_dt)

train_mse_dt
test_mse_dt
```
#Висновок: значення середньоквадратичної похибки покращилися на навчальній вибірці – 1.51, погіршилися на тестовій вибірці – 2.187. Модель перенавчено.

## Visualising
```{r}
library(ggplot2)
x_grid <- seq(min(f_train$Population), max(f_train$Population), 0.01)
ggplot() +
  geom_point(aes(f_train$Population, f_train$Homicide),colour = 'olivedrab4') +
  geom_point(aes(f_test$Population, f_test$Homicide),colour = 'orangered') +
  geom_line(aes(x_grid, predict(model_dt, data.frame(Population = x_grid))),colour = 'magenta3') +
  ggtitle('Homicide vs Population') +
  xlab('Population') +
  ylab('Homicide')
```
#Висновок: на графіку червоним позначені точки навчальної вибірки, зеленим – точки тестової вибірки, синім – модельні значення.

# Random forest

## Fitting
```{r}
# install.packages('randomForest')
library(randomForest)
set.seed(1234)
model_rf = randomForest(x = f_train['Population'],
                         y = f_train$Homicide,
                         ntree = 50)
```

#Висновок: побудовано віпадковий ліс із 50 дерев, екзогенна змінна – Population.

## Predicting
```{r}
p_rf <- predict(model_rf, f_test)

train_mse_rf <- sum((f_train$Homicide-predict(model_rf, f_train))^2)/length(f_train$Homicide)
test_mse_rf <- sum((f_test$Homicide-p_rf)^2)/length(p_rf)

train_mse_rf
test_mse_rf
```

#Висновок: значення середньоквадратичної похибки покращилися на навчальній вибірці – 0.715, покращилися на тестовій вибірці – 2,152. Модель перенавчено.

## Visualising
```{r}
ggplot() +
  geom_point(aes(f_train$Population, f_train$Homicide),colour = 'olivedrab4') +
  geom_point(aes(f_test$Population, f_test$Homicide),colour = 'orangered') +
  geom_line(aes(x_grid, predict(model_rf, data.frame(Population = x_grid))),colour = 'magenta3') +
  ggtitle('Homicide vs Population') +
  xlab('Population') +
  ylab('Homicide')
```
#Висновок: на графіку червоним позначені точки навчальної вибірки, зеленим – точки тестової вибірки, синім – модельні значення.

# Saving results
```{r}
fit <- read.csv2('crime_fit.csv', header = TRUE, encoding = 'UNICOD')
fit$p_dt <- p_dt
fit$p_rf <- p_rf
head(fit)
write.csv2(fit[-1], file = "crime_fit.csv")
```