---
title: "lab2_luzanova_ep61"
output:
  word_document: default
  html_notebook: default
  pdf_document: default
  html_document: default
---

# Download the data
```{r}
#Source files are here
#setwd('D:/luzanova')

##Features scaling is included in the packages we will work with

#Download the files
f_train <- read.csv2('crime_train.csv', header = TRUE, encoding = 'UNICOD')
f_train <- f_train[,-c(1,2,18)]
f_test <- read.csv2('crime_test.csv', header = TRUE, encoding = 'UNICOD')
f_test <- f_test[,-c(1,2,18)]
```

#Висновок: окремо задані навчальна і тестова вибірки, видалені перші стовпчики з індексами об’єктів до кожної з підвибірок.

# Simple Linear Regression (one factor - Population )

## Fitting Simple Linear Regression to the Training set
```{r}
model_sr <- lm(Homicide ~ Population , f_train)
summary(model_sr)
```
#Висновок: коефіцієнт детермінації 0,68.  змінна - значуща

## Predicting
```{r}
p_sr <- predict(model_sr, f_test)

r2_sr <- 1-sum((f_train$Homicide - predict(model_sr, f_train))^2)/sum((f_train$Homicide - mean(f_train$Homicide))^2)
R2_sr <- cor(f_train$Homicide, fitted(model_sr))^2 #simplier ex.

train_mse_sr <- sum((f_train$Homicide-predict(model_sr, f_train))^2)/length(f_train$Homicide)
test_mse_sr <- sum((f_test$Homicide-p_sr)^2)/length(p_sr)

r2_sr
R2_sr
train_mse_sr
test_mse_sr
```

#Висновок: вручну розраховані коефіцієнти детермінації. Значення середньоквадратичної похибки на навчальній вибірці – 1,696, на тестовій вибірці – 2,232, тобто є перенавчання.

## Visualising
```{r}
library(ggplot2)
ggplot() +
  geom_point(aes(f_train$Population, f_train$Homicide),colour = 'red') +
  geom_point(aes(f_test$Population, f_test$Homicide),colour = 'darkgreen') +
  geom_line(aes(f_test$Population, p_sr),colour = 'blue') +
  ggtitle('Homicide vs Population') +
  xlab('Population') +
  ylab('Homicide')
```

#Висновок: на графіку червоним позначені точки навчальної вибірки, зеленим – точки тестової вибірки, синім – модельні значення.
# Multiple Linear Regression (many factors)

## All factors
```{r}
model_mr <- lm(data = f_train, Homicide ~ .) 
summary(model_mr)  
```

#удалим из модели всі змінні, окрім Population, Life_expect, Empl_serv, RegionAmericas 

## Optimized model
```{r}

model_opt <- lm(data = f_train, Homicide ~ Population + Life_expect  +  Empl_serv) 
summary(model_opt)  
```

## Prediction
```{r}
p_mr <- predict(model_opt, f_test)

train_mse_opt <- sum((f_train$Homicide-predict(model_opt, f_train))^2)/length(f_train$Homicide)
test_mse_opt <- sum((f_test$Homicide-p_mr)^2)/length(p_mr)

train_mse_opt
test_mse_opt
```
#Висновок. Значення середньоквадратичної похибки на навчальній вибірці – 1,204, на тестовій вибірці – 2,227, тобто є перенавчання.

## Visualising
```{r}
ggplot() +
  geom_point(aes(f_train$Population, f_train$Homicide),colour = 'red') +
  geom_point(aes(f_test$Population, f_test$Homicide),colour = 'dark green') +
  geom_line(aes(f_test$Population, p_mr),colour = 'blue') +
  ggtitle('Homicide vs Population') +
  xlab('Population') +
  ylab('Homicide')
```

# Polynomial Linear Regression (one factor - Population)

## Features extending 
```{r}
f_train_poly <- f_train[,c('Homicide', 'Population')]
f_test_poly <- f_test[,c('Homicide', 'Population')]
f_train_poly$Population2 <- f_train_poly$Population^2
f_train_poly$Population3 <- f_train_poly$Population^3
f_test_poly$Population2 <- f_test_poly$Population^2
f_test_poly$Population3 <- f_test_poly$Population^3
```

## 3 powers
```{r}
model_pr <- lm(data = f_train_poly, Homicide ~ Population2 + Population3) 
summary(model_pr)  
```
#Висновок. Значення R-squared покращилось 
## Predicting
```{r}
p_pr <- predict(model_pr, f_test_poly)

train_mse_poly <- sum((f_train_poly$Homicide-predict(model_pr, f_train_poly))^2)/length(f_train_poly$Homicide)
test_mse_poly <- sum((f_test_poly$Homicide-p_pr)^2)/length(p_pr)

train_mse_poly
test_mse_poly
```

#Висновок. Значення середньоквадратичної похибки на навчальній вибірці – 1,685, на тестовій вибірці – 2,056, тобто є перенавчання.

## Visualising
```{r}
ggplot() +
  geom_point(aes(f_train_poly$Population, f_train_poly$Homicide),colour = 'red') +
  geom_point(aes(f_test_poly$Population, f_test_poly$Homicide),colour = 'dark green') +
  geom_line(aes(f_test_poly$Population, p_pr),colour = 'blue') +
  ggtitle('Homicide vs Population') +
  xlab('Population') +
  ylab('Homicide')
```

# Saving results
```{r}
fit <- data.frame(p_sr, p_mr, p_pr)
write.csv2(fit, file = "crime_fit.csv")
```